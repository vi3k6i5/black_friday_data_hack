{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical columns that i chose\n",
    "categorical_columns = [\"Product_ID\", \"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Stay_In_Current_City_Years\",\n",
    "                       \"Marital_Status\", \"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label\n",
    "train_y = np.array(train[\"Purchase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train.copy()\n",
    "test_X = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.fillna(0)\n",
    "test_X = test_X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I came up with a feature on what is the avg amount spent on a product id\n",
    "# I tried a lot of other options here\n",
    "# 1. Purchase price avg by gender, age group, product category 1, product category 2, product category 3\n",
    "product_id_res = train_X.groupby([\"Product_ID\"])[\"Purchase\"].mean()\n",
    "avg_cost = train_X[\"Purchase\"].mean()\n",
    "# If i find a product id for which i dont have an avg pricing i will use global vg pricing.\n",
    "product_id_res_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# created a map with product id to avg price map\n",
    "val = product_id_res.iteritems()\n",
    "for key, value in val:\n",
    "    p_id = str(key)\n",
    "    product_id_res_map[p_id] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_purchase_mean(product_id, product_category=None, key=None):\n",
    "    key_pair = str(product_id)\n",
    "    key_pair_pid = str(product_id) + str(product_category)\n",
    "    if key == \"1\":\n",
    "        if key_pair_pid in product_category_1_res:\n",
    "            return product_category_1_res[key_pair_pid]\n",
    "    elif key == \"2\":\n",
    "        if key_pair_pid in product_category_2_res:\n",
    "            return product_category_2_res[key_pair_pid]\n",
    "    elif key == \"3\":\n",
    "        if key_pair_pid in product_category_3_res:\n",
    "            return product_category_3_res[key_pair_pid]\n",
    "    if key_pair in product_id_res:\n",
    "        return product_id_res[key_pair]\n",
    "    return avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a feature with pruduct_id to avg price of that product map\n",
    "train_X[\"purchase_avg_by_p_id\"] = map(lambda product_id: get_purchase_mean(product_id), train_X[\"Product_ID\"])\n",
    "test_X[\"purchase_avg_by_p_id\"] = map(lambda product_id: get_purchase_mean(product_id), test_X[\"Product_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another feature that i created was\n",
    "# Use_id to purchase power category\n",
    "# Basically i came up with a distribution of purchase sum by suer.\n",
    "# Created 10 hard coded buckets around it.\n",
    "# The ipython notebook has more detail on this\n",
    "user_id_to_category_map = {}\n",
    "customer_purchase_power = train_X.groupby(\"User_ID\")[\"Purchase\"].sum()\n",
    "values = customer_purchase_power.iteritems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, val in values:\n",
    "    if val <= 146570.0:\n",
    "        user_id_to_category_map[key] = 1\n",
    "    elif val <= 205272.0:\n",
    "        user_id_to_category_map[key] = 2\n",
    "    elif val <= 279288.0:\n",
    "        user_id_to_category_map[key] = 3\n",
    "    elif val <= 383455.0:\n",
    "        user_id_to_category_map[key] = 4\n",
    "    elif val <= 521213.0:\n",
    "        user_id_to_category_map[key] = 5\n",
    "    elif val <= 698842.0:\n",
    "        user_id_to_category_map[key] = 6\n",
    "    elif val <= 942900.0:\n",
    "        user_id_to_category_map[key] = 7\n",
    "    elif val <= 1355245.0:\n",
    "        user_id_to_category_map[key] = 8\n",
    "    elif val <= 2069404.0:\n",
    "        user_id_to_category_map[key] = 9\n",
    "    else:\n",
    "        user_id_to_category_map[key] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_customer_category(user_id):\n",
    "    if user_id in user_id_to_category_map:\n",
    "        return user_id_to_category_map[user_id]\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tagged each user with a category id\n",
    "train_X[\"user_category\"] = map(lambda user_id: get_customer_category(user_id), train_X[\"User_ID\"])\n",
    "test_X[\"user_category\"] = map(lambda user_id: get_customer_category(user_id), test_X[\"User_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding categorical variable with label encoding\n",
    "for var in categorical_columns:\n",
    "    lb = preprocessing.LabelEncoder()\n",
    "    full_var_data = pd.concat((train_X[var], test_X[var]), axis=0).astype('str')\n",
    "    lb.fit(full_var_data)\n",
    "    train_X[var] = lb.transform(train_X[var].astype('str'))\n",
    "    test_X[var] = lb.transform(test_X[var].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.drop(['Purchase'], axis=1)\n",
    "\n",
    "train_X = np.array(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model\n"
     ]
    }
   ],
   "source": [
    "# I built 3 models to make precictions\n",
    "# Finally i did an avg of the 3 and submitted that.\n",
    "print \"1st model\"\n",
    "# 1st model\n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"early_stopping_rounds\"] = 10\n",
    "params[\"seed\"] = 42\n",
    "plst = list(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "num_rounds = 1420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_y_xgb1 = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd model\n"
     ]
    }
   ],
   "source": [
    "print \"2nd model\"\n",
    "# 2nd model\n",
    "# NOTE: I have changed the paramertes since i last uploaded the results. so the final score might vary.\n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"early_stopping_rounds\"] = 10\n",
    "params[\"seed\"] = 333\n",
    "plst = list(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code shuffels the train matrix.\n",
    "# In ensures that the oder of feature shuffel and label shuffel is same\n",
    "\n",
    "merged_train_x_and_y = np.c_[train_X.reshape(len(train_X), -1), train_y.reshape(len(train_y), -1)]\n",
    "\n",
    "shuffled_train_x = merged_train_x_and_y[:, :train_X.size//len(train_X)].reshape(train_X.shape)\n",
    "shuffled_train_y = merged_train_x_and_y[:, train_X.size//len(train_X):].reshape(train_y.shape)\n",
    "\n",
    "np.random.shuffle(merged_train_x_and_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffled train matrix is now shuffled_train_x\n",
    "xgtrain = xgb.DMatrix(shuffled_train_x, label=shuffled_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_y_xgb2 = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd model\n"
     ]
    }
   ],
   "source": [
    "print \"3rd model\"\n",
    "# 3rd model\n",
    "# NOTE: I have changed the paramertes since i last uploaded the results. so the final score might vary.\n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"early_stopping_rounds\"] = 10\n",
    "params[\"seed\"] = 777\n",
    "plst = list(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffled train matrix again.\n",
    "merged_train_x_and_y = np.c_[train_X.reshape(len(train_X), -1), train_y.reshape(len(train_y), -1)]\n",
    "\n",
    "shuffled_train_x = merged_train_x_and_y[:, :train_X.size//len(train_X)].reshape(train_X.shape)\n",
    "shuffled_train_y = merged_train_x_and_y[:, train_X.size//len(train_X):].reshape(train_y.shape)\n",
    "\n",
    "np.random.shuffle(merged_train_x_and_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(shuffled_train_x, label=shuffled_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_y_xgb3 = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Purchase'] = (pred_test_y_xgb1 + pred_test_y_xgb2 + pred_test_y_xgb3) / 3\n",
    "test.to_csv('final_xgb.csv', columns=['User_ID', 'Product_ID', 'Purchase'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
